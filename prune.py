import torch
import torch.nn.utils.prune as prune
from ultralytics import YOLO
from copy import deepcopy
import csv
import os

# é…ç½®é¡¹
model_path = 'yolov8s-pose.pt'  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
data_yaml = '/home/zhengxiuzhang/ultralytics-main/coco8-pose.yaml'  # æ›¿æ¢ä¸ºä½ çš„æ•°æ®é…ç½®æ–‡ä»¶
sparsity_level = 0.1  # å‰ªææ¯”ä¾‹
csv_file = 'prune_sensitivity.csv'
save_model_dir = 'pruned_models'
os.makedirs(save_model_dir, exist_ok=True)

# æ¨¡å—ç»„
module_groups = [
    ('Backbone_CBS1', ['model.0']),
    ('Backbone_CBS2', ['model.1']),
    ('Backbone_C2f1', ['model.2']),
    ('Backbone_CBS3', ['model.3']),
    ('Backbone_C2f2', ['model.4']),
    ('Backbone_CBS4', ['model.5']),
    ('Backbone_C2f3', ['model.6']),
    ('Backbone_CBS5', ['model.7']),
    ('Backbone_SPPF', ['model.8']),
    ('Neck_FPN1', ['model.9']),
    ('Neck_PAN1', ['model.10']),
    ('Neck_Upsample1', ['model.11']),
    ('Neck_Concat1', ['model.12']),
    ('Neck_FPN2', ['model.13']),
    ('Neck_PAN2', ['model.14']),
    ('Neck_Upsample2', ['model.15']),
    ('Neck_Concat2', ['model.16']),
    ('Head_Detect', ['model.17']),
    ('Head_Pose', ['model.18']),
    ('Head_key_point1', ['model.19']),
    ('Head_key_point2', ['model.20']),
    ('Head_key_point3', ['model.21'])
]

# ç¨€ç–ç‡è®¡ç®—å‡½æ•°
def compute_sparsity(layer):
    if not hasattr(layer, 'weight'):
        return 0.0
    total = layer.weight.numel()
    zeros = (layer.weight == 0).sum().item()
    return zeros / total

# å†™å…¥ CSV å¤´
with open(csv_file, mode='w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['Group Name', 'Sparsity', 'Actual Sparsity (%)', 'mAP@50', 'mAP@50-95', 'Precision', 'Recall'])

    base_yolo = YOLO(model_path)

    for group_name, group_layers in module_groups:
        print(f'\nğŸ”§ æ­£åœ¨å‰ªææ¨¡å—ç»„: {group_name}')

        # æ·±æ‹·è´ YOLO æ¨¡å‹
        temp_yolo = deepcopy(base_yolo)
        temp_model = temp_yolo.model
        total_sparsity = []

        # å¯¹æŒ‡å®šæ¨¡å—å‰ªæ
        for layer_name in group_layers:
            try:
                layer = temp_model.get_submodule(layer_name)
            except AttributeError:
                print(f"âŒ æ‰¾ä¸åˆ°å±‚: {layer_name}")
                continue

            if isinstance(layer, torch.nn.Conv2d):
                prune.l1_unstructured(layer, name='weight', amount=sparsity_level)
                with torch.no_grad():
                    layer.weight_orig[layer.weight_mask == 0] = 0
                prune.remove(layer, 'weight')  # âœ… çœŸæ­£ç§»é™¤æ©ç 
                sparsity = compute_sparsity(layer)
                total_sparsity.append(sparsity)
                print(f"âœ… {layer_name} å‰ªæå®Œæˆï¼Œå®é™…ç¨€ç–ç‡: {sparsity:.2%}")
            else:
                print(f"âš ï¸ è·³è¿‡éConv2då±‚: {layer_name}")

        # éªŒè¯å‰ªæåçš„æ¨¡å‹
        metrics = temp_yolo.val(data=data_yaml, split='val')

        # æå–æŒ‡æ ‡
        map50 = metrics.pose.map50
        map5095 = metrics.pose.map
        precision = metrics.pose.p
        recall = metrics.pose.r
        avg_sparsity = sum(total_sparsity) / len(total_sparsity) * 100 if total_sparsity else 0

        print(f'ğŸ“Š {group_name} ç»“æœ: mAP@50 = {map50:.4f}, mAP@50-95 = {map5095:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}')

        # å†™å…¥ç»“æœ
        writer.writerow([
            group_name, sparsity_level, f"{avg_sparsity:.2f}%",
            float(map50), float(map5095), float(precision), float(recall)
        ])

        # ä¿å­˜æ¨¡å‹
        save_path = os.path.join(save_model_dir, f'{group_name}_pruned.pt')
        temp_yolo.save(save_path)
        print(f'ğŸ’¾ å‰ªææ¨¡å‹å·²ä¿å­˜è‡³: {save_path}')

print(f'\nâœ… æ‰€æœ‰å‰ªæç»“æœå·²ä¿å­˜è‡³ CSV: {os.path.abspath(csv_file)}')
